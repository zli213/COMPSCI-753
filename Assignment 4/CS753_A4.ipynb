{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'user_id': '26d5737b1eaff71248069cde4f590338', 'book_id': '30109111', 'review_id': 'd567c1be612401ee5cbe3da05683561f', 'rating': 5, 'date_added': 'Sun Jun 12 09:38:16 -0700 2016'}, {'user_id': 'e0a970290631fd711484f0d8155f2a06', 'book_id': '7198269', 'review_id': '1fca74b92a06f2cccdc81c1288687495', 'rating': 5, 'date_added': 'Thu May 10 18:37:25 -0700 2012'}, {'user_id': 'cca945e8a7369eeb035afd21527c339b', 'book_id': '32148570', 'review_id': 'e519d8377a10308742dd49f66f4a728a', 'rating': 3, 'date_added': 'Mon May 29 10:32:28 -0700 2017'}, {'user_id': 'd1789d248a75d3cb7c5f16eeee9fe419', 'book_id': '40024', 'review_id': 'a75d9f435773a377fbe81361a1ea19c6', 'rating': 2, 'date_added': 'Mon Jan 26 21:04:34 -0800 2009'}, {'user_id': '819f2797459b579a7782d4bd595e1c36', 'book_id': '3272163', 'review_id': 'cfbc4e10f33bad3bd235f775e1833b2d', 'rating': 3, 'date_added': 'Wed Jun 25 12:12:10 -0700 2014'}, {'user_id': '7d0b0d563843507c71f867720801d84e', 'book_id': '361056', 'review_id': '41556ee650e292fe914816abf9455062', 'rating': 1, 'date_added': 'Fri Oct 19 06:54:29 -0700 2007'}, {'user_id': 'b85e8348c1e1f6ed6ae8e76bb6de7f15', 'book_id': '10855973', 'review_id': 'be2a3aa400602d43bdbc5c5196235088', 'rating': 5, 'date_added': 'Thu May 17 13:29:51 -0700 2012'}, {'user_id': '17d3a7342670ec8c47777296bfe71709', 'book_id': '15802432', 'review_id': '398c3f730486a30af1cf9be55700d5d1', 'rating': 4, 'date_added': 'Sun Apr 14 07:38:58 -0700 2013'}, {'user_id': '750e558376102be2392d6f80a77c186f', 'book_id': '53645', 'review_id': '808757067ba063061a494142cbaeab1f', 'rating': 4, 'date_added': 'Mon Jun 09 10:53:05 -0700 2008'}, {'user_id': 'ac87d8e90ac47cd3cc69baf88857650e', 'book_id': '2318271', 'review_id': '8e0e4899a50359a17221a7d50e8c6890', 'rating': 5, 'date_added': 'Sun May 12 17:32:10 -0700 2013'}]\n",
      "The number of data is:  1239715\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_data(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    return data\n",
    "\n",
    "train_data = read_data(\"goodreads_reviews_historybio_train.json\")\n",
    "# print the first 10 line of the data\n",
    "print(train_data[:10])\n",
    "# print the number of data\n",
    "print(\"The number of data is: \", len(train_data))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 [10 points]: Explore biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global bias: 3.7669762808387413\n",
      "User bias for user 3913f3be1e8fadc1de34dc49dab06381: -0.1139150563489455\n",
      "Item bias for book 16130: 0.4562653093753264\n"
     ]
    }
   ],
   "source": [
    "def calculate_global_bias(data):\n",
    "    total_rating = sum([review['rating'] for review in data])\n",
    "    return total_rating / len(data)\n",
    "\n",
    "def calculate_sum_and_count(data):\n",
    "    user_sums = {}\n",
    "    user_counts = {}\n",
    "    item_sums = {}\n",
    "    item_counts = {}\n",
    "    \n",
    "    for review in data:\n",
    "        user_id = review['user_id']\n",
    "        item_id = review['book_id']\n",
    "        rating = review['rating']\n",
    "        \n",
    "        user_sums[user_id] = user_sums.get(user_id, 0) + rating\n",
    "        user_counts[user_id] = user_counts.get(user_id, 0) + 1\n",
    "        \n",
    "        item_sums[item_id] = item_sums.get(item_id, 0) + rating\n",
    "        item_counts[item_id] = item_counts.get(item_id, 0) + 1\n",
    "        \n",
    "    return user_sums, user_counts, item_sums, item_counts\n",
    "\n",
    "def calculate_all_user_bias_optimized(user_sums, user_counts, global_bias):\n",
    "    return {user: (user_sums[user]/user_counts[user]) - global_bias for user in user_sums}\n",
    "\n",
    "def calculate_all_item_bias_optimized(item_sums, item_counts, global_bias):\n",
    "    return {item: (item_sums[item]/item_counts[item]) - global_bias for item in item_sums}\n",
    "# A\n",
    "bg = calculate_global_bias(train_data)\n",
    "print(f\"Global bias: {bg}\")\n",
    "\n",
    "user_sums, user_counts, item_sums, item_counts = calculate_sum_and_count(train_data)\n",
    "all_user_biases = calculate_all_user_bias_optimized(user_sums, user_counts, bg)\n",
    "all_item_biases = calculate_all_item_bias_optimized(item_sums, item_counts, bg)\n",
    "\n",
    "user_id = \"3913f3be1e8fadc1de34dc49dab06381\"\n",
    "book_id = \"16130\"\n",
    "# B\n",
    "print(f\"User bias for user {user_id}: {all_user_biases[user_id]}\")\n",
    "# C\n",
    "print(f\"Item bias for book {book_id}: {all_item_biases[book_id]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 [45 points]: Implement the regularized latent factor model without bias using SGD\n",
    "(A) [30 points] Implement the regularized latent factor model without considering the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report the RMSE on the training data for each epoch:\n",
      "Epoch 1: RMSE = 3.9712275565759962\n",
      "Epoch 2: RMSE = 3.920560461286309\n",
      "Epoch 3: RMSE = 3.3634407088134237\n",
      "Epoch 4: RMSE = 2.8056054187920463\n",
      "Epoch 5: RMSE = 2.4359231907821552\n",
      "Epoch 6: RMSE = 2.171073773692028\n",
      "Epoch 7: RMSE = 1.9716202196493424\n",
      "Epoch 8: RMSE = 1.8148277056015418\n",
      "Epoch 9: RMSE = 1.688415492674227\n",
      "Epoch 10: RMSE = 1.5842972397232302\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def initialization(k, datasets):\n",
    "    # Extract all unique users and items from all datasets\n",
    "    all_users = set()\n",
    "    all_items = set()\n",
    "    for data in datasets:\n",
    "        all_users.update([d['user_id'] for d in data])\n",
    "        all_items.update([d['book_id'] for d in data])\n",
    "    \n",
    "    num_users = len(all_users)\n",
    "    num_items = len(all_items)\n",
    "    \n",
    "    P = np.random.normal(scale=0.01, size=(num_users, k))\n",
    "    Q = np.random.normal(scale=0.01, size=(num_items, k))\n",
    "    \n",
    "    user_map = {user_id: idx for idx, user_id in enumerate(all_users)}\n",
    "    item_map = {book_id: idx for idx, book_id in enumerate(all_items)}\n",
    "    \n",
    "    return P, Q, user_map, item_map\n",
    "\n",
    "def SGD(data, P, Q, user_map, item_map, eta, lambda1, lambda2, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        np.random.shuffle(data)\n",
    "        squared_errors = []\n",
    "        \n",
    "        for review in data:\n",
    "            i = user_map[review['user_id']]\n",
    "            j = item_map[review['book_id']]\n",
    "            r_ij = review['rating']\n",
    "            e_ij = r_ij - np.dot(Q[j], P[i])\n",
    "            \n",
    "            # Update using gradients\n",
    "            temp_q = Q[j, :]\n",
    "            Q[j, :] += 2 * eta * (e_ij * P[i, :] - lambda1 * Q[j, :])\n",
    "            P[i, :] += 2 * eta * (e_ij * temp_q - lambda2 * P[i, :])\n",
    "            \n",
    "            squared_errors.append(e_ij ** 2)\n",
    "        \n",
    "        rmse = np.sqrt(sum(squared_errors) / len(data))\n",
    "        print(f\"Epoch {epoch+1}: RMSE = {rmse}\")\n",
    "    \n",
    "    return P, Q\n",
    "\n",
    "def compute_RMSE(data, P, Q, user_map, item_map):\n",
    "    squared_errors = []\n",
    "    for review in data:\n",
    "        i = user_map.get(review['user_id'], None)\n",
    "        j = item_map.get(review['book_id'], None)\n",
    "        if i is None or j is None:\n",
    "            continue\n",
    "        r_ij = review['rating']\n",
    "        e_ij = r_ij - np.dot(Q[j], P[i])\n",
    "        squared_errors.append(e_ij ** 2)\n",
    "    rmse = np.sqrt(sum(squared_errors) / len(data))\n",
    "    return rmse\n",
    "\n",
    "train_data = read_data(\"goodreads_reviews_historybio_train.json\")\n",
    "validation_data = read_data(\"goodreads_reviews_historybio_val.json\")\n",
    "test_data = read_data(\"goodreads_reviews_historybio_test.json\")\n",
    "# (A)\n",
    "k = 8\n",
    "eta = 0.01\n",
    "lambda1 = lambda2 = 0.3\n",
    "epochs = 10\n",
    "\n",
    "# Initialization for all datasets (train, validation, test)\n",
    "P, Q, user_map, item_map = initialization(k, [train_data, validation_data, test_data])\n",
    "\n",
    "# Report the RMSE on the training data for each epoch\n",
    "print(\"Report the RMSE on the training data for each epoch:\")\n",
    "P,Q = SGD(train_data, P, Q, user_map, item_map, eta, lambda1, lambda2, epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (B) [15 points] Use SGD to train the latent factor model on the training data for different values of k in {4,8,16}. Pick the model that results in the best RMSE on the validation set and report its RMSE on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: RMSE = 3.9712380849997726\n",
      "Epoch 2: RMSE = 3.939066854177271\n",
      "Epoch 3: RMSE = 3.4277956704025527\n",
      "Epoch 4: RMSE = 2.848231186744928\n",
      "Epoch 5: RMSE = 2.4671284941425067\n",
      "Epoch 6: RMSE = 2.194073526069323\n",
      "Epoch 7: RMSE = 1.9895334844537524\n",
      "Epoch 8: RMSE = 1.8297656368639728\n",
      "Epoch 9: RMSE = 1.700921355294477\n",
      "Epoch 10: RMSE = 1.5953063723279999\n",
      "-------------------------------------------\n",
      "k=4: Validation RMSE = 2.164384796192713\n",
      "-------------------------------------------\n",
      "Epoch 1: RMSE = 3.9712195886468415\n",
      "Epoch 2: RMSE = 3.912394887490233\n",
      "Epoch 3: RMSE = 3.3443390603790064\n",
      "Epoch 4: RMSE = 2.793915745824147\n",
      "Epoch 5: RMSE = 2.4278254130035135\n",
      "Epoch 6: RMSE = 2.164925273109161\n",
      "Epoch 7: RMSE = 1.9664348410254582\n",
      "Epoch 8: RMSE = 1.8103438125324618\n",
      "Epoch 9: RMSE = 1.6843064691462886\n",
      "Epoch 10: RMSE = 1.5807749159855573\n",
      "-------------------------------------------\n",
      "k=8: Validation RMSE = 2.1622865101297593\n",
      "-------------------------------------------\n",
      "Epoch 1: RMSE = 3.971210543962408\n",
      "Epoch 2: RMSE = 3.904706427000633\n",
      "Epoch 3: RMSE = 3.322847201229169\n",
      "Epoch 4: RMSE = 2.780045080844826\n",
      "Epoch 5: RMSE = 2.4174964984498595\n",
      "Epoch 6: RMSE = 2.1565853009900207\n",
      "Epoch 7: RMSE = 1.9596241187733656\n",
      "Epoch 8: RMSE = 1.8043764693192836\n",
      "Epoch 9: RMSE = 1.6787774831646942\n",
      "Epoch 10: RMSE = 1.5754666023484354\n",
      "-------------------------------------------\n",
      "k=16: Validation RMSE = 2.161165901679926\n",
      "-------------------------------------------\n",
      "Best k value for Validation set: 16\n",
      "-------------------------------------------\n",
      "Epoch 1: RMSE = 3.9711865271064717\n",
      "Epoch 2: RMSE = 3.881633877759073\n",
      "Epoch 3: RMSE = 3.2742760572342946\n",
      "Epoch 4: RMSE = 2.752069680917696\n",
      "Epoch 5: RMSE = 2.3989862224038716\n",
      "Epoch 6: RMSE = 2.1428158009952627\n",
      "Epoch 7: RMSE = 1.948896968867091\n",
      "Epoch 8: RMSE = 1.7958665604917383\n",
      "Epoch 9: RMSE = 1.672196174934591\n",
      "Epoch 10: RMSE = 1.5707256399124656\n",
      "-------------------------------------------\n",
      "Test RMSE with best k value: 2.1589878593310954\n"
     ]
    }
   ],
   "source": [
    "k_values = [4, 8, 16]\n",
    "best_rmse = float('inf')\n",
    "best_k = None\n",
    "for k in k_values:\n",
    "    P, Q, user_map, item_map = initialization(k, [train_data, validation_data, test_data])\n",
    "    SGD(train_data, P, Q, user_map, item_map, eta, lambda1, lambda2, epochs)\n",
    "    \n",
    "    rmse_val = compute_RMSE(validation_data, P, Q, user_map, item_map)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(f\"k={k}: Validation RMSE = {rmse_val}\")\n",
    "    print(\"-------------------------------------------\")\n",
    "\n",
    "    if rmse_val < best_rmse:\n",
    "        best_rmse = rmse_val\n",
    "        best_k = k\n",
    "\n",
    "print(f\"Best k value for Validation set: {best_k}\")\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "# Compute RMSE on test data for the best k value\n",
    "P_best, Q_best, user_map_best, item_map_best = initialization(best_k, [train_data, validation_data, test_data])\n",
    "SGD(train_data, P_best, Q_best, user_map_best, item_map_best, eta, lambda1, lambda2, epochs)\n",
    "rmse_test = compute_RMSE(test_data, P_best, Q_best, user_map_best, item_map_best)\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"Test RMSE with best k value: {rmse_test}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 [45 points]: Implement the regularized latent factor model with bias using SGD\n",
    "(A) [30 points] Incorporate the bias terms bg, b(user) and b(item) to the latent factor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to SGD with bias\n",
      "Epoch 1: RMSE = 0.9011646626295965\n",
      "Epoch 2: RMSE = 0.893854481855423\n",
      "Epoch 3: RMSE = 0.8887689401512124\n",
      "Epoch 4: RMSE = 0.8854306106361683\n",
      "Epoch 5: RMSE = 0.882725747261069\n",
      "Epoch 6: RMSE = 0.8806881257645449\n",
      "Epoch 7: RMSE = 0.8792244036607717\n",
      "Epoch 8: RMSE = 0.8771279643236278\n",
      "Epoch 9: RMSE = 0.8762063416685426\n",
      "Epoch 10: RMSE = 0.8746691021799325\n",
      "-------------------------------------------\n",
      "User bias for user 3913f3be1e8fadc1de34dc49dab06381: 0.020714971569287772\n",
      "Item specific bias for book id 16130: 0.4697761519984729\n"
     ]
    }
   ],
   "source": [
    "def initialization_bias(k, datasets):\n",
    "    # Extract all unique users and items from all datasets\n",
    "    all_users = set()\n",
    "    all_items = set()\n",
    "    for data in datasets:\n",
    "        all_users.update([d['user_id'] for d in data])\n",
    "        all_items.update([d['book_id'] for d in data])\n",
    "    \n",
    "    num_users = len(all_users)\n",
    "    num_items = len(all_items)\n",
    "    \n",
    "    P = np.random.normal(scale=0.01, size=(num_users, k))\n",
    "    Q = np.random.normal(scale=0.01, size=(num_items, k))\n",
    "    \n",
    "    user_map = {user_id: idx for idx, user_id in enumerate(all_users)}\n",
    "    item_map = {book_id: idx for idx, book_id in enumerate(all_items)}\n",
    "    \n",
    "    # Initialize biases based on computed user and item biases\n",
    "    b_users = {user: all_user_biases.get(user, 0.0) for user in user_map.keys()}\n",
    "    b_items = {item: all_item_biases.get(item, 0.0) for item in item_map.keys()}\n",
    "    \n",
    "    return P, Q, user_map, item_map, b_users, b_items\n",
    "\n",
    "def SGD_with_bias(data, P, Q, user_map, item_map, eta, lambda1, lambda2, lambda3, lambda4, bg, b_user, b_item, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        np.random.shuffle(data)\n",
    "        for review in data:\n",
    "            i = user_map[review['user_id']]\n",
    "            j = item_map[review['book_id']]\n",
    "            r_ij_actual = review['rating']\n",
    "            user_bias = b_users.get(review['user_id'], 0.0)\n",
    "            item_bias = b_items.get(review['book_id'], 0.0)\n",
    "            r_ij_predicted = bg + user_bias + item_bias + np.dot(Q[j], P[i])\n",
    "            e_ij = r_ij_actual - r_ij_predicted\n",
    "\n",
    "            # Update using gradients\n",
    "            temp_q = Q[j, :]\n",
    "            Q[j, :] += 2*eta * (e_ij * P[i, :] - lambda1 * Q[j, :])\n",
    "            P[i, :] += 2*eta * (e_ij * temp_q - lambda2 * P[i, :])\n",
    "\n",
    "            # Update biases\n",
    "            b_users[review['user_id']] += 2*eta * (e_ij - lambda3 * b_users[review['user_id']])\n",
    "            b_items[review['book_id']] += 2*eta * (e_ij - lambda4 * b_items[review['book_id']])\n",
    "\n",
    "        rmse_train = compute_rmse_bias(P,Q, bg, b_users, b_items, data, user_map, item_map)\n",
    "        print(f\"Epoch {epoch+1}: RMSE = {rmse_train}\")\n",
    "    return P, Q, b_users, b_items\n",
    "def compute_rmse_bias(P, Q, bg, b_users, b_items, data, user_map, item_map):\n",
    "    squared_errors = []\n",
    "    for review in data:\n",
    "        i = user_map[review['user_id']]\n",
    "        j = item_map[review['book_id']]\n",
    "        r_ij = review['rating']\n",
    "        user_bias = b_users.get(review['user_id'], 0.0)\n",
    "        item_bias = b_items.get(review['book_id'], 0.0)\n",
    "        squared_errors.append((r_ij - (bg + user_bias + item_bias + np.dot(Q[j], P[i]))) ** 2)\n",
    "    rmse = np.sqrt(sum(squared_errors) / len(squared_errors))\n",
    "    return rmse\n",
    "\n",
    "lambda1 = lambda2 = lambda3 =lambda4 =0.3\n",
    "user_id = \"3913f3be1e8fadc1de34dc49dab06381\"\n",
    "book_id = \"16130\"\n",
    "# bg = calculate_global_bias(train_data)\n",
    "# b_user = calculate_user_bias(train_data, user_id, bg)\n",
    "# b_item = calculate_item_bias(train_data, book_id, bg)\n",
    "P, Q, user_map, item_map, b_users, b_items = initialization_bias(k, [train_data, validation_data, test_data])\n",
    "print(\"Start to SGD with bias\")\n",
    "SGD_with_bias(train_data, P, Q, user_map, item_map, eta, lambda1, lambda2, lambda3, lambda4, bg, b_users, b_items, epochs=10)\n",
    "print(\"-------------------------------------------\")\n",
    "\n",
    "# After finishing all epoches, report the learned user-specific bias of the user with user id= “3913f3be1e8fadc1de34dc49dab06381” , and the learned item- specific bias of the book with book id = “16130”.\n",
    "print(f\"User bias for user {user_id}: {b_users[user_id]}\")\n",
    "print(f\"Item specific bias for book id {book_id}: {b_items[book_id]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) [15 points] Similar to Task 2 (B), find the best k in {4, 8, 16} for the model you developed in Task 3 (A) on the validation set, by using RMSE to compare across these models, and apply the best of these models to the test data. Compare the resulting test RMSE with Task 2 (B). Analyse and explain your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start SGD_with_bias with 4 for train data\n",
      "-------------------------------------------\n",
      "Epoch 1: RMSE = 0.9010579451355839\n",
      "Epoch 2: RMSE = 0.8936768966616953\n",
      "Epoch 3: RMSE = 0.8887608725517381\n",
      "Epoch 4: RMSE = 0.8853275303909918\n",
      "Epoch 5: RMSE = 0.8826880894968575\n",
      "Epoch 6: RMSE = 0.880534731585201\n",
      "Epoch 7: RMSE = 0.878938365012461\n",
      "Epoch 8: RMSE = 0.8776251687289484\n",
      "Epoch 9: RMSE = 0.875965960436849\n",
      "Epoch 10: RMSE = 0.8746998481853213\n",
      "-------------------------------------------\n",
      "k=4: Validation RMSE = 1.195111743486199\n",
      "-------------------------------------------\n",
      "Start SGD_with_bias with 8 for train data\n",
      "-------------------------------------------\n",
      "Epoch 1: RMSE = 0.9011016318671035\n",
      "Epoch 2: RMSE = 0.8935007035799424\n",
      "Epoch 3: RMSE = 0.8889571637738545\n",
      "Epoch 4: RMSE = 0.8851471368418924\n",
      "Epoch 5: RMSE = 0.8829126739313063\n",
      "Epoch 6: RMSE = 0.8802978559211005\n",
      "Epoch 7: RMSE = 0.878731508269502\n",
      "Epoch 8: RMSE = 0.877275045043425\n",
      "Epoch 9: RMSE = 0.8758617357234114\n",
      "Epoch 10: RMSE = 0.8748647581812774\n",
      "-------------------------------------------\n",
      "k=8: Validation RMSE = 1.19514479186164\n",
      "-------------------------------------------\n",
      "Start SGD_with_bias with 16 for train data\n",
      "-------------------------------------------\n",
      "Epoch 1: RMSE = 0.9011650621958573\n",
      "Epoch 2: RMSE = 0.8937248919117944\n",
      "Epoch 3: RMSE = 0.8888067539915859\n",
      "Epoch 4: RMSE = 0.8852032048737393\n",
      "Epoch 5: RMSE = 0.8826356294533626\n",
      "Epoch 6: RMSE = 0.8805758445756415\n",
      "Epoch 7: RMSE = 0.8789189135487402\n",
      "Epoch 8: RMSE = 0.8772390284459345\n",
      "Epoch 9: RMSE = 0.8761333560584174\n",
      "Epoch 10: RMSE = 0.8748494588413068\n",
      "-------------------------------------------\n",
      "k=16: Validation RMSE = 1.1958184526992803\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "Best k value (Task 3): 4\n",
      "-------------------------------------------\n",
      "Start SGD_with_bias whith best k for train data\n",
      "Epoch 1: RMSE = 0.873770651027615\n",
      "Epoch 2: RMSE = 0.8732049832965025\n",
      "Epoch 3: RMSE = 0.8719722022323918\n",
      "Epoch 4: RMSE = 0.871891036173968\n",
      "Epoch 5: RMSE = 0.8707191783625375\n",
      "Epoch 6: RMSE = 0.8706578753376226\n",
      "Epoch 7: RMSE = 0.8703038210945345\n",
      "Epoch 8: RMSE = 0.8690428136720262\n",
      "Epoch 9: RMSE = 0.8689965797621265\n",
      "Epoch 10: RMSE = 0.8683077000674218\n",
      "-------------------------------------------\n",
      "Test RMSE with best k value (Task 3): 1.181270686761496\n"
     ]
    }
   ],
   "source": [
    "k_values = [4, 8, 16]\n",
    "best_rmse = float('inf')\n",
    "best_k = None\n",
    "user_id = \"3913f3be1e8fadc1de34dc49dab06381\"\n",
    "book_id = \"16130\"\n",
    "bg = calculate_global_bias(train_data)\n",
    "\n",
    "for k in k_values:\n",
    "    P, Q, user_map, item_map, b_users, b_items = initialization_bias(k, [train_data, validation_data, test_data])\n",
    "    print(\"Start SGD_with_bias with \"+str(k)+\" for train data\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    SGD_with_bias(train_data, P, Q, user_map, item_map, eta,lambda1, lambda2, lambda3, lambda4, bg, b_users, b_items, 10)\n",
    "    rmse_val = compute_rmse_bias(P,Q, bg, b_users, b_items, validation_data ,user_map, item_map)\n",
    "    print(\"-------------------------------------------\")\n",
    "    print(f\"k={k}: Validation RMSE = {rmse_val}\")\n",
    "    print(\"-------------------------------------------\")\n",
    "    if rmse_val < best_rmse:\n",
    "        best_rmse = rmse_val\n",
    "        best_k = k\n",
    "\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"Best k value (Task 3): {best_k}\")\n",
    "print(\"-------------------------------------------\")\n",
    "# Use the best model for test data\n",
    "P_best, Q_best, user_map_best, item_map_best,b_users_best, b_items_best = initialization_bias(best_k, [train_data, validation_data, test_data])\n",
    "print(\"Start SGD_with_bias whith best k for train data\")\n",
    "P_best, Q_best, b_users, b_items = SGD_with_bias(train_data, P_best, Q_best, user_map_best, item_map_best, eta, lambda1, lambda2, lambda3, lambda4, bg, b_users_best, b_items_best, 10)\n",
    "rmse_test = compute_rmse_bias(P_best, Q_best, bg, b_users, b_items, test_data, user_map_best, item_map_best)\n",
    "print(\"-------------------------------------------\")\n",
    "print(f\"Test RMSE with best k value (Task 3): {rmse_test}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:**\n",
    "\n",
    "1. **Lower RMSE in Task 3(B) compared to Task 2(B):**\n",
    "    - The inclusion of bias terms in the latent factor model (Task 3(B)) led to a better fit to the data, resulting in a lower RMSE. This suggests that incorporating user and item-specific biases can capture inherent characteristics in the data, enhancing prediction accuracy.\n",
    "\n",
    "2. **Higher optimal \\( k \\) value in Task 2(B) than in Task 3(B):**\n",
    "    - The model in Task 3(B) required a smaller number of latent factors \\( k \\) to achieve optimal performance, likely because the added bias terms already captured some intrinsic properties of users and items. This indicates that the bias-enhanced model can achieve comparable or better performance using fewer latent factors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
